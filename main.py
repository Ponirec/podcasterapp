from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request, BackgroundTasks
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

from pathlib import Path
from typing import Dict, Any, Tuple, Optional
import time

import sys
import types
import os
import logging
import hashlib
import uuid

# --------------------------------------
# Compatibilidad pydub / audioop / pyaudioop
# --------------------------------------
try:
    import pyaudioop as audioop  # type: ignore
except ImportError:
    try:
        import audioop  # type: ignore
        fake = types.ModuleType("pyaudioop")
        for name in dir(audioop):
            setattr(fake, name, getattr(audioop, name))
        sys.modules["pyaudioop"] = fake
    except ImportError:
        audioop = None  # type: ignore

from pydub import AudioSegment, effects


# =========================
#   LOGGING
# =========================
logger = logging.getLogger("podcasterapp")
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)


# =========================
#   POSTGRES (M칄TRICAS)
# =========================
def _truthy(v: Optional[str]) -> bool:
    return str(v or "").strip().lower() in {"1", "true", "yes", "y", "on"}

ENABLE_DB_METRICS = _truthy(os.getenv("ENABLE_DB_METRICS", "0"))
DATABASE_URL = os.getenv("DATABASE_URL", "").strip()
METRICS_SALT = os.getenv("METRICS_SALT", "").strip() or "change-me"  # c치mbialo en Render

# Intentamos soportar psycopg2 (recomendado) o psycopg (v3)
DB_DRIVER = None
try:
    import psycopg2  # type: ignore
    DB_DRIVER = "psycopg2"
except Exception:
    try:
        import psycopg  # type: ignore
        DB_DRIVER = "psycopg"
    except Exception:
        DB_DRIVER = None

def db_metrics_ready() -> bool:
    if not ENABLE_DB_METRICS:
        return False
    if not DATABASE_URL:
        return False
    if DB_DRIVER is None:
        return False
    return True

CREATE_TABLE_SQL = """
CREATE TABLE IF NOT EXISTS request_metrics (
  id UUID PRIMARY KEY,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  mode TEXT,
  client_ip_hash TEXT,
  user_agent TEXT,

  input_filename TEXT,
  input_bytes BIGINT,
  output_bytes BIGINT,
  report_bytes BIGINT,

  duration_original_s DOUBLE PRECISION,
  duration_processed_s DOUBLE PRECISION,

  processing_ms INTEGER,

  quality_score INTEGER,
  snr_db DOUBLE PRECISION,
  sala_indice DOUBLE PRECISION,
  clip_detectado BOOLEAN
);
"""

INSERT_SQL = """
INSERT INTO request_metrics (
  id, mode, client_ip_hash, user_agent,
  input_filename, input_bytes, output_bytes, report_bytes,
  duration_original_s, duration_processed_s,
  processing_ms,
  quality_score, snr_db, sala_indice, clip_detectado
) VALUES (
  %(id)s, %(mode)s, %(client_ip_hash)s, %(user_agent)s,
  %(input_filename)s, %(input_bytes)s, %(output_bytes)s, %(report_bytes)s,
  %(duration_original_s)s, %(duration_processed_s)s,
  %(processing_ms)s,
  %(quality_score)s, %(snr_db)s, %(sala_indice)s, %(clip_detectado)s
);
"""

def _anonymize_ip(ip: Optional[str]) -> Optional[str]:
    if not ip:
        return None
    h = hashlib.sha256((METRICS_SALT + "|" + ip).encode("utf-8")).hexdigest()
    return h[:16]  # corto y suficiente para contar 칰nicos sin guardar IP real

def _exec_sql(sql: str, params: Optional[dict] = None) -> None:
    """
    Ejecuta SQL. Si falla, solo loggea (no rompe flujo).
    """
    if not db_metrics_ready():
        return

    try:
        if DB_DRIVER == "psycopg2":
            import psycopg2  # type: ignore
            conn = psycopg2.connect(DATABASE_URL)
            conn.autocommit = True
            try:
                with conn.cursor() as cur:
                    cur.execute(sql, params)
            finally:
                conn.close()

        elif DB_DRIVER == "psycopg":
            import psycopg  # type: ignore
            with psycopg.connect(DATABASE_URL, autocommit=True) as conn:
                with conn.cursor() as cur:
                    cur.execute(sql, params)

    except Exception as e:
        logger.warning(f"[DB_METRICS] Error ejecutando SQL: {e}")

def init_db() -> None:
    if not db_metrics_ready():
        if ENABLE_DB_METRICS and DB_DRIVER is None:
            logger.warning("[DB_METRICS] ENABLE_DB_METRICS=1 pero no hay driver instalado (psycopg2/psycopg).")
        return
    _exec_sql(CREATE_TABLE_SQL)
    logger.info("[DB_METRICS] Tabla request_metrics lista.")

def record_metrics(payload: dict) -> None:
    _exec_sql(INSERT_SQL, payload)


# =========================
#   RUTAS DE ARCHIVOS
# =========================
BASE_DIR = Path(__file__).resolve().parent
MEDIA_DIR = BASE_DIR / "media"
ORIGINAL_DIR = MEDIA_DIR / "original"
PROCESSED_DIR = MEDIA_DIR / "processed"
REPORT_DIR = MEDIA_DIR / "reports"
STATIC_DIR = BASE_DIR / "static"

for d in (ORIGINAL_DIR, PROCESSED_DIR, REPORT_DIR):
    d.mkdir(parents=True, exist_ok=True)

# =========================
#   L칈MITE DE TAMA칌O DE ARCHIVO
# =========================
MAX_FILE_SIZE_MB = 20
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024

# =========================
#   APP FASTAPI + CORS
# =========================
app = FastAPI()

origins = [
    "http://127.0.0.1:5500",
    "http://localhost:5500",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Servir /media desde FastAPI
app.mount("/media", StaticFiles(directory=str(MEDIA_DIR)), name="media")
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")

@app.on_event("startup")
def _startup():
    init_db()

# Ruta ra칤z: sirve index.html
@app.get("/", response_class=HTMLResponse)
async def root():
    index_path = STATIC_DIR / "index.html"
    return index_path.read_text(encoding="utf-8")

@app.get("/health")
async def health():
    return {
        "ok": True,
        "db_metrics_enabled": ENABLE_DB_METRICS,
        "db_driver": DB_DRIVER,
        "db_url_present": bool(DATABASE_URL),
    }

# =========================
#   L칍GICA DE AUDIO
# =========================
def analizar_audio(audio: AudioSegment) -> Dict[str, Any]:
    """Devuelve m칠tricas b치sicas del audio original, 칤ndice de sala, SNR y clipping."""

    dur_ms = len(audio)

    nivel_dbfs = float(audio.dBFS) if audio.dBFS != float("-inf") else -90.0

    chunk_ms = 200
    niveles = []
    for i in range(0, dur_ms, chunk_ms):
        c = audio[i: i + chunk_ms]
        v = float(c.dBFS) if c.dBFS != float("-inf") else -90.0
        niveles.append(v)

    niveles.sort()
    if niveles:
        n_sub = max(1, len(niveles) // 4)
        ruido_estimado = sum(niveles[:n_sub]) / n_sub
    else:
        ruido_estimado = -90.0

    ruido_estimado = max(ruido_estimado, -80.0)

    snr = nivel_dbfs - ruido_estimado

    if snr >= 55 and ruido_estimado <= -75:
        sala_indice = 0.1
        sala_desc = (
            "muy controlada (poca sala perceptible: micr칩fono muy cerca o espacio con buena absorci칩n)"
        )
    elif snr >= 35 and ruido_estimado <= -60:
        sala_indice = 0.4
        sala_desc = "bastante controlada (pieza amoblada con varias cosas blandas)"
    elif snr >= 20:
        sala_indice = 0.7
        sala_desc = "con bastante reflexi칩n (t칤pico living o pieza con poco tratamiento)"
    else:
        sala_indice = 1.0
        sala_desc = "muy viva / con mucha reflexi칩n (espacio duro o casi vac칤o, eco marcado)"

    sample_width = audio.sample_width
    max_possible = float((1 << (8 * sample_width - 1)) - 1)

    samples = audio.get_array_of_samples()
    if samples:
        max_abs = max(abs(s) for s in samples)
        peak_ratio = max_abs / max_possible
        clip_samples = sum(1 for s in samples if abs(s) >= 0.98 * max_possible)
        clip_ratio = clip_samples / len(samples)
    else:
        peak_ratio = 0.0
        clip_ratio = 0.0

    peak_db = audio.max_dBFS if audio.max_dBFS != float("-inf") else -90.0
    crest_factor = peak_db - nivel_dbfs

    clip_detectado = (peak_ratio > 0.985) and (clip_ratio > 0.0005)

    if clip_detectado:
        clip_desc = (
            "Se detectan picos muy cercanos al m치ximo digital de forma repetida. "
            "Es probable que haya algo de distorsi칩n/clip en la grabaci칩n original."
        )
    elif peak_ratio > 0.96:
        clip_desc = (
            "Tu se침al llega muy cerca del m치ximo digital. No se ve clip claro, "
            "pero est치s al l칤mite: conviene bajar un poco la ganancia."
        )
    else:
        clip_desc = (
            "No se detectan se침ales claras de clip digital en la grabaci칩n."
        )

    return {
        "sala_descripcion": sala_desc,
        "sala_indice": round(sala_indice, 2),
        "ruido_estimado_dbfs": round(ruido_estimado, 1),
        "nivel_original_dbfs": round(nivel_dbfs, 1),
        "snr_db": round(snr, 1),
        "peak_dbfs": round(peak_db, 1),
        "crest_factor_db": round(crest_factor, 1),
        "clip_detectado": clip_detectado,
        "clip_ratio": round(clip_ratio, 5),
        "clip_descripcion": clip_desc,
    }

def calcular_quality(a: Dict[str, Any], modo: str) -> Tuple[int, str]:
    score = 45

    snr = a.get("snr_db", 0.0)
    sala = a.get("sala_indice", 0.5)
    nivel_orig = a.get("nivel_original_dbfs", -24.0)
    clip = a.get("clip_detectado", False)

    snr_clamped = max(10.0, min(40.0, snr))
    snr_contrib = (snr_clamped - 10.0) * (20.0 / 30.0)
    score += snr_contrib

    score += (1.0 - min(max(sala, 0.0), 1.0)) * 15.0

    if -26 <= nivel_orig <= -16:
        score += 10
    elif -32 <= nivel_orig < -26 or -16 < nivel_orig <= -10:
        score += 5
    else:
        score -= 5

    if clip:
        score -= 30
        score -= snr_contrib * 0.3

    if "Laptop / Celular" in modo:
        score -= 5
    elif "Micr칩fono externo" in modo:
        score += 5

    score = int(max(0, min(100, round(score))))

    if score < 40:
        label = "Necesita bastante trabajo antes de publicar"
    elif score < 70:
        label = "Aceptable, pero con margen de mejora"
    elif score < 85:
        label = "Listo para podcast con peque침os ajustes"
    else:
        label = "Nivel muy s칩lido / casi profesional"

    return score, label

def recortar_final_despues_de_voz(
    audio: AudioSegment,
    chunk_ms: int = 150,
    umbral_rel_db: float = 25.0,
    margen_ms: int = 400,
    min_silencio_ms: int = 2000,
) -> AudioSegment:
    dur = len(audio)
    if dur <= chunk_ms * 2:
        return audio

    max_db = audio.max_dBFS if audio.max_dBFS != float("-inf") else -90.0
    limite_db = max_db - umbral_rel_db

    ultimo_util_ms = None

    for inicio in range(dur - chunk_ms, -1, -chunk_ms):
        trozo = audio[inicio: inicio + chunk_ms]
        nivel = trozo.dBFS if trozo.dBFS != float("-inf") else -90.0

        if nivel > limite_db:
            ultimo_util_ms = inicio + chunk_ms
            break

    if ultimo_util_ms is None:
        return audio

    silencio_ms = dur - ultimo_util_ms

    if silencio_ms < min_silencio_ms:
        return audio

    corte_ms = min(dur, ultimo_util_ms + margen_ms)
    return audio[:corte_ms]

def limpiar_golpe_tecla_final(
    audio: AudioSegment,
    ventana_ms: int = 180,
    umbral_db: float = -25.0,
    diferencia_db: float = 8.0,
) -> AudioSegment:
    dur = len(audio)
    if dur < ventana_ms * 2:
        return audio

    inicio_ultima = dur - ventana_ms
    inicio_prev = dur - 2 * ventana_ms

    bloque_prev = audio[inicio_prev:inicio_ultima]
    bloque_ult = audio[inicio_ultima:dur]

    prev_db = bloque_prev.dBFS if bloque_prev.dBFS != float("-inf") else -90.0
    ult_db = bloque_ult.dBFS if bloque_ult.dBFS != float("-inf") else -90.0

    if (ult_db > umbral_db) and (ult_db - prev_db >= diferencia_db):
        return audio[:inicio_ultima]

    return audio

def procesar_audio_core(original_path: Path, modo: str) -> Tuple[Path, Dict[str, Any]]:
    audio = AudioSegment.from_file(original_path)

    analisis = analizar_audio(audio)

    TRIM_INICIO_MS = 300
    TRIM_FINAL_MS = 700

    dur_ms = len(audio)

    if dur_ms > (TRIM_INICIO_MS + TRIM_FINAL_MS):
        audio_proc_base = audio[TRIM_INICIO_MS : dur_ms - TRIM_FINAL_MS]
    elif dur_ms > TRIM_INICIO_MS:
        audio_proc_base = audio[TRIM_INICIO_MS:]
    else:
        audio_proc_base = audio

    audio_proc_base = audio_proc_base.high_pass_filter(80)
    audio_proc = effects.normalize(audio_proc_base)

    # 游댷 NUEVO: peque침o fade out global al final (120 ms aprox)
    audio_proc = audio_proc.fade_out(120)

    analisis["nivel_final_dbfs"] = round(
        float(audio_proc.dBFS) if audio_proc.dBFS != float("-inf") else -90.0, 1
    )
    analisis["modo"] = (
        "Laptop / Celular"
        if modo == "LAPTOP_CELULAR"
        else "Micr칩fono externo (USB / interfaz)"
    )
    analisis["duracion_original_s"] = round(dur_ms / 1000.0, 2)
    analisis["duracion_procesada_s"] = round(len(audio_proc) / 1000.0, 2)

    quality_score, quality_label = calcular_quality(analisis, analisis["modo"])
    analisis["quality_score"] = quality_score
    analisis["quality_label"] = quality_label

    processed_name = f"{original_path.stem}_PROCESADO.wav"
    processed_path = PROCESSED_DIR / processed_name
    audio_proc.export(processed_path, format="wav")

    return processed_path, analisis

def construir_informe_texto(nombre_original: str, a: Dict[str, Any]) -> str:
    lineas = []
    lineas.append("=== Informe de procesamiento de audio ===")
    lineas.append("")
    lineas.append(f"Archivo: {nombre_original}")
    lineas.append("")
    lineas.append("== Resumen general ==")

    delta_nivel = a["nivel_final_dbfs"] - a["nivel_original_dbfs"]

    lineas.append(
        f"Procesamos tu audio en modo {a['modo']}. "
        f"Tu sala se eval칰a como {a['sala_descripcion']} (칤ndice {a['sala_indice']}). "
        f"El ruido de fondo estimado est치 en torno a {a['ruido_estimado_dbfs']} dBFS. "
        f"La voz qued칩 aproximadamente {delta_nivel:+.1f} dB respecto de la grabaci칩n original "
        f"despu칠s del procesamiento."
    )
    lineas.append("")
    lineas.append(
        "Como parte del proceso, recortamos autom치ticamente un peque침o tramo al inicio "
        "y, cuando el audio es lo suficientemente largo, otro peque침o tramo al final para "
        "limpiar clics, ruidos de inicio/stop y silencios innecesarios."
    )
    lineas.append("")

    lineas.append("== Datos clave ==")
    lineas.append(f"- Modo: {a['modo']}")
    lineas.append(f"- Sala: {a['sala_descripcion']} (칤ndice {a['sala_indice']})")
    lineas.append(f"- Ruido estimado: {a['ruido_estimado_dbfs']} dBFS")
    lineas.append(f"- Nivel de voz original: {a['nivel_original_dbfs']} dBFS")
    lineas.append(f"- Nivel de voz final: {a['nivel_final_dbfs']} dBFS")
    lineas.append(f"- Relaci칩n se침al/ruido aproximada: {a.get('snr_db', 0.0)} dB")
    lineas.append(f"- Pico m치ximo aproximado: {a.get('peak_dbfs', 0.0)} dBFS")
    lineas.append(f"- Crest factor aproximado: {a.get('crest_factor_db', 0.0)} dB")
    lineas.append(
        f"- Clips / distorsi칩n digital: "
        f"{'Probables' if a.get('clip_detectado') else 'No se detectan claros indicios'}"
    )
    lineas.append(
        f"- Puntaje de calidad: {a.get('quality_score', '-')} / 100 "
        f"({a.get('quality_label', '')})"
    )
    lineas.append("")

    lineas.append("== Qu칠 hizo la app con tu archivo ==")
    lineas.append("- Analiz칩 el nivel de tu voz, el ruido de fondo y el comportamiento de la sala.")
    lineas.append("- Recort칩 un peque침o tramo al inicio para limpiar ruidos de arranque y respiraciones muy pegadas.")
    lineas.append(
        "- Cuando la duraci칩n lo permiti칩, recort칩 ligeramente el final para reducir clics de stop y silencios largos."
    )
    lineas.append("- Aplic칩 un filtro pasa altos suave para limpiar graves innecesarios.")
    lineas.append("- Ajust칩 el nivel global para dejar tu voz en un rango m치s c칩modo para escucha tipo podcast.")
    lineas.append("")

    lineas.append("== Comentario sobre clipping ==")
    lineas.append(a.get("clip_descripcion", "Sin datos de clipping."))
    lineas.append("")

    modo = a.get("modo", "")
    nivel_orig = a.get("nivel_original_dbfs", -20.0)
    snr = a.get("snr_db", 0.0)
    sala_ind = a.get("sala_indice", 0.5)
    clip = a.get("clip_detectado", False)

    recomendaciones = []

    if "Laptop" in modo:
        recomendaciones.append(
            "Est치s grabando con el micr칩fono del equipo (laptop / celular). "
            "Si puedes, da el salto a un micr칩fono externo sencillo (USB o interfaz), "
            "vas a notar una mejora grande en claridad y ruido."
        )
    else:
        recomendaciones.append(
            "Est치s grabando con un micr칩fono externo. Es una muy buena base para lograr "
            "un sonido de podcast m치s profesional."
        )

    if nivel_orig <= -30:
        recomendaciones.append(
            "Tu nivel de voz original lleg칩 bastante bajo. Para la pr칩xima, ac칠rcate un poco m치s "
            "al micr칩fono y/o sube la ganancia del preamp hasta que tu voz quede alrededor de "
            "-24 a -18 dBFS en los picos normales de habla."
        )
    elif -24 <= nivel_orig <= -16:
        if clip:
            recomendaciones.append(
                "Aunque el nivel medio de tu voz no es extremo, se detecta distorsi칩n por estar muy al l칤mite. "
                "Baja un poco la ganancia de entrada o al칠jate unos cent칤metros del micr칩fono para evitar clip digital."
            )
        else:
            recomendaciones.append(
                "El nivel de voz original est치 dentro de un rango saludable para mezcla. "
                "Solo necesitas mantener la distancia y el volumen que usaste al grabar."
            )
    elif nivel_orig > -16:
        recomendaciones.append(
            "Tu nivel de voz original lleg칩 bastante alto. Si en alg칰n momento escuchas distorsi칩n, "
            "baja un poco la ganancia del micr칩fono o al칠jate unos cent칤metros para evitar el clipeo."
        )

    if snr < 18:
        recomendaciones.append(
            "Hay bastante ruido de fondo (baja relaci칩n se침al/ruido). Revisa si puedes apagar ventiladores, "
            "PC muy ruidosos, o cerrar ventanas para reducir tr치fico y ruidos de ambiente."
        )
    elif 18 <= snr < 30:
        recomendaciones.append(
            "El ruido de fondo es moderado. Para mejorar todav칤a m치s, intenta grabar cuando el entorno est칠 "
            "m치s silencioso (noche / horarios tranquilos) o al칠jate de fuentes de ruido constantes."
        )
    else:
        recomendaciones.append(
            "La relaci칩n se침al/ruido es buena: tu voz est치 claramente por encima del ruido de fondo. "
            "Es un buen punto de partida para procesar sin artefactos agresivos."
        )

    if sala_ind >= 0.75:
        recomendaciones.append(
            "La sala suena bastante viva (muchas reflexiones). Para mejorar, suma absorci칩n casera alrededor: "
            "frazadas, colchones, sof치s, cortinas gruesas, alfombras y ropa ayudan mucho a matar el eco."
        )
    elif 0.4 < sala_ind < 0.75:
        recomendaciones.append(
            "Tu sala tiene algo de reflexi칩n, pero est치 en un rango manejable. Si quieres un sonido a칰n m치s seco, "
            "a침ade un poco m치s de material blando alrededor del punto de grabaci칩n."
        )
    else:
        recomendaciones.append(
            "Tu sala est치 bastante controlada en reflexiones. Es un muy buen entorno para grabar voz, "
            "solo cuida el nivel de ruido de fondo y la distancia al micr칩fono."
        )

    if abs(delta_nivel) < 1.0:
        recomendaciones.append(
            "La app casi no tuvo que corregir el nivel global porque tu grabaci칩n ya ven칤a bien "
            "equilibrada en volumen."
        )
    elif delta_nivel > 0:
        recomendaciones.append(
            "La app subi칩 el nivel general de la voz para llevarla a un rango m치s consistente de escucha."
        )
    else:
        recomendaciones.append(
            "La app baj칩 el nivel general de la voz para evitar picos demasiado altos y dejar m치s margen "
            "para la mezcla y master."
        )

    if clip:
        recomendaciones.append(
            "Al detectar probable clip digital, es recomendable repetir la toma con un poco menos de ganancia "
            "si se trata de un material importante (entrevista, episodio principal, etc.)."
        )

    recomendaciones.append(
        "Para aprovechar mejor la app, deja alrededor de 1 segundo de silencio antes de empezar a hablar "
        "y otro segundo al terminar. Eso ayuda a limpiar clics de teclado, ruidos de stop y respiraciones bruscas."
    )

    lineas.append("== C칩mo mejorar tu pr칩xima grabaci칩n ==")
    for rec in recomendaciones:
        lineas.append(f"- {rec}")
    lineas.append("")

    return "\n".join(lineas)

# =========================
#   ENDPOINT
# =========================
@app.post("/api/process_audio")
async def process_audio(
    request: Request,
    background_tasks: BackgroundTasks,
    audio_file: UploadFile = File(...),
    mode: str = Form(...),
):
    t0 = time.perf_counter()

    raw_bytes = await audio_file.read(MAX_FILE_SIZE_BYTES + 1)

    if len(raw_bytes) > MAX_FILE_SIZE_BYTES:
        raise HTTPException(
            status_code=413,
            detail=(
                f"El archivo es demasiado pesado. "
                f"Tama침o m치ximo permitido: {MAX_FILE_SIZE_MB} MB. "
                "Prueba subiendo un extracto m치s corto de tu audio."
            ),
        )

    safe_suffix = audio_file.filename.replace(" ", "_")
    safe_name = f"{int(time.time())}_{safe_suffix}"

    original_path = ORIGINAL_DIR / safe_name
    with original_path.open("wb") as f:
        f.write(raw_bytes)

    processed_path, analysis = procesar_audio_core(original_path, mode)

    report_name = f"{processed_path.stem}_report.txt"
    report_path = REPORT_DIR / report_name
    report_text = construir_informe_texto(safe_name, analysis)
    report_path.write_text(report_text, encoding="utf-8")

    processing_ms = int(round((time.perf_counter() - t0) * 1000.0))

    # --- M칄TRICAS (NO ROMPEN FLUJO) ---
    if db_metrics_ready():
        try:
            ip = request.client.host if request.client else None
            ua = request.headers.get("user-agent")

            payload = {
                "id": str(uuid.uuid4()),
                "mode": analysis.get("modo"),
                "client_ip_hash": _anonymize_ip(ip),
                "user_agent": ua,

                "input_filename": safe_name,
                "input_bytes": int(len(raw_bytes)),
                "output_bytes": int(processed_path.stat().st_size) if processed_path.exists() else None,
                "report_bytes": int(report_path.stat().st_size) if report_path.exists() else None,

                "duration_original_s": float(analysis.get("duracion_original_s")) if analysis.get("duracion_original_s") is not None else None,
                "duration_processed_s": float(analysis.get("duracion_procesada_s")) if analysis.get("duracion_procesada_s") is not None else None,

                "processing_ms": processing_ms,

                "quality_score": int(analysis.get("quality_score")) if analysis.get("quality_score") is not None else None,
                "snr_db": float(analysis.get("snr_db")) if analysis.get("snr_db") is not None else None,
                "sala_indice": float(analysis.get("sala_indice")) if analysis.get("sala_indice") is not None else None,
                "clip_detectado": bool(analysis.get("clip_detectado")) if analysis.get("clip_detectado") is not None else None,
            }

            background_tasks.add_task(record_metrics, payload)
        except Exception as e:
            logger.warning(f"[DB_METRICS] No se pudieron preparar m칠tricas: {e}")

    return JSONResponse(
        {
            "original_url": f"/media/original/{safe_name}",
            "processed_url": f"/media/processed/{processed_path.name}",
            "report_url": f"/media/reports/{report_name}",
            "original_filename": audio_file.filename,
            "analysis": analysis,
        }
    )
